{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Module 1:**"
      ],
      "metadata": {
        "id": "I7_jHv0trr8I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5Gz6BAornvd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Function to read the CSV file into a DataFrame\n",
        "def read_csv():\n",
        "    # read the user_nodes.csv file using pandas library and return it\n",
        "    df = pd.read_csv('user_nodes.csv')\n",
        "    return df\n",
        "\n",
        "\n",
        "# Function to check for null (missing) values in the DataFrame\n",
        "def check_null_values():\n",
        "    # do not edit the predefined function name\n",
        "    df = read_csv()\n",
        "    # Check for null values using the isnull() method and sum them for each column\n",
        "    null_values = df.isnull().sum()\n",
        "    return null_values\n",
        "\n",
        "# Function to check for duplicate rows in the DataFrame\n",
        "def check_duplicates():\n",
        "    # do not edit the predefined function name\n",
        "    df = read_csv()\n",
        "    # Calculate the number of duplicate rows using the duplicated() method and sum them\n",
        "    duplicates = df.duplicated().sum()\n",
        "    return duplicates\n",
        "\n",
        "\n",
        "\n",
        "# Function to drop duplicate rows from the DataFrame\n",
        "def drop_duplicates():\n",
        "    # do not edit the predefined function name\n",
        "    df = read_csv()\n",
        "    # Drop duplicate rows using the drop_duplicates() method with inplace=True\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def data_cleaning():\n",
        "    df = drop_duplicates()\n",
        "\n",
        "    # Step 3: Drop specified columns from the DataFrame (\"has_loan\", \"is_act\")\n",
        "    df.drop([\"has_loan\", \"is_act\"], axis=1, inplace=True)\n",
        "\n",
        "    # Step 4: Rename columns\n",
        "    df.rename(columns={'id_': 'consumer_id', 'area_id_': 'region_id', 'node_id_': 'node_id', 'act_date': 'start_date', 'deact_date': 'end_date'}, inplace=True)\n",
        "\n",
        "    # Step 5: Export the cleaned DataFrame to a CSV file without the index column\n",
        "    df.to_csv('user_nodes_cleaned.csv', index=False)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Module 2:**"
      ],
      "metadata": {
        "id": "ugnGbtMBrvTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Function to read the CSV file into a DataFrame\n",
        "def read_csv():\n",
        "    # read the user_transactions.csv file using pandas library and return it\n",
        "    df = pd.read_csv('user_transactions.csv')\n",
        "    return df\n",
        "\n",
        "# Function to check for null (missing) values in the DataFrame\n",
        "def check_null_values():\n",
        "    # do not edit the predefined function name\n",
        "    df = read_csv()\n",
        "    # Check for null values using the isnull() method and sum them for each column\n",
        "    null_values = df.isnull().sum()\n",
        "    return null_values\n",
        "\n",
        "# Function to check for duplicate values in the DataFrame\n",
        "def check_duplicates():\n",
        "    # do not edit the predefined function name\n",
        "    df = read_csv()\n",
        "    # Calculate the number of duplicate rows using the duplicated() method and sum them\n",
        "    duplicates = df.duplicated().sum()\n",
        "    return duplicates\n",
        "\n",
        "\n",
        "\n",
        "# Function to drop duplicate rows from the DataFrame\n",
        "def drop_duplicates():\n",
        "    # do not edit the predefined function name\n",
        "    df = read_csv()\n",
        "    # Drop duplicate rows using the drop_duplicates() method with inplace=True\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def data_cleaning():\n",
        "    \"\"\"\n",
        "    Data Cleaning Function:\n",
        "    Cleans the DataFrame by dropping specified columns and renaming others.\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: The cleaned DataFrame after dropping and renaming columns.\n",
        "    \"\"\"\n",
        "    # Step 1: Get the DataFrame with duplicate rows removed and rows with null values dropped\n",
        "    df = drop_duplicates()\n",
        "\n",
        "    # Step 2: Columns to remove from the DataFrame\n",
        "    columns_to_remove = [\"has_credit_card\", \"account_type\"]\n",
        "    # Drop specified columns from the DataFrame\n",
        "    df.drop(columns=columns_to_remove, inplace=True)\n",
        "\n",
        "    # Step 3: Rename columns using the new column names\n",
        "    df.rename(columns={'id_': 'consumer_id', 't_date': 'transaction_date', 't_type': 'transaction_type', 't_amt': 'transaction_amount'}, inplace=True)\n",
        "\n",
        "    # Step 4: Export the cleaned DataFrame to a CSV file without the index column\n",
        "    df.to_csv('user_transaction_cleaned.csv', index=False)\n",
        "    return df"
      ],
      "metadata": {
        "id": "n1gizAzkrxS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Module 3: SQL QUERIES**"
      ],
      "metadata": {
        "id": "IGLITw7Zr_0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT wr.region_name, COUNT(DISTINCT un.consumer_id) AS num_users\n",
        "FROM world_regions wr\n",
        "LEFT JOIN user_nodes un ON wr.region_id = un.region_id\n",
        "GROUP BY wr.region_name;\n",
        "============================\n",
        "SELECT ut.consumer_id, ut.transaction_type, MAX(ut.transaction_amount) AS largest_deposit\n",
        "FROM user_transaction ut\n",
        "WHERE ut.transaction_type = 'deposit'\n",
        "GROUP BY ut.consumer_id, ut.transaction_type\n",
        "ORDER BY largest_deposit DESC\n",
        "LIMIT 2;\n",
        "=========================================\n",
        "SELECT un.consumer_id, SUM(ut.transaction_amount) AS total_amount_deposited\n",
        "FROM user_transaction AS ut\n",
        "JOIN user_nodes AS un\n",
        "ON ut.consumer_id = un.consumer_id\n",
        "JOIN world_regions AS wr\n",
        "ON un.region_id = wr.region_id\n",
        "WHERE wr.region_name = 'Europe'\n",
        "AND ut.transaction_type = 'deposit'\n",
        "GROUP BY un.consumer_id;\n",
        "=========================================\n",
        "SELECT u.consumer_id, COUNT(t.consumer_id) AS total_transactions\n",
        "FROM user_nodes u\n",
        "INNER JOIN user_transaction t ON u.consumer_id = t.consumer_id\n",
        "INNER JOIN world_regions r ON u.region_id = r.region_id\n",
        "WHERE r.region_name = 'United States'\n",
        "GROUP BY u.consumer_id;\n",
        "==============================\n",
        "SELECT t.consumer_id, COUNT(*) AS num_transactions\n",
        "FROM user_transaction t\n",
        "GROUP BY t.consumer_id\n",
        "HAVING COUNT(*) > 5;\n",
        "=========================================\n",
        "SELECT r.region_name, COUNT(u.node_id) AS num_nodes\n",
        "FROM world_regions r\n",
        "LEFT JOIN user_nodes u ON r.region_id = u.region_id\n",
        "GROUP BY r.region_name\n",
        "HAVING COUNT(u.node_id) > 0;\n",
        "==========================================\n",
        "SELECT u.consumer_id, MAX(t.transaction_amount) AS largest_deposit_amount\n",
        "FROM user_nodes u\n",
        "INNER JOIN user_transaction t ON u.consumer_id = t.consumer_id\n",
        "INNER JOIN world_regions r ON u.region_id = r.region_id\n",
        "WHERE r.region_name = 'Australia' AND t.transaction_type = 'deposit'\n",
        "GROUP BY u.consumer_id\n",
        "ORDER BY largest_deposit_amount DESC\n",
        "LIMIT 1;\n",
        "====================================\n",
        "SELECT u.consumer_id, r.region_name, SUM(t.transaction_amount) AS total_deposit_amount\n",
        "FROM user_nodes u\n",
        "INNER JOIN user_transaction t ON u.consumer_id = t.consumer_id\n",
        "INNER JOIN world_regions r ON u.region_id = r.region_id\n",
        "WHERE t.transaction_type = 'deposit'\n",
        "GROUP BY u.consumer_id, r.region_name;\n",
        "===========================================\n",
        "SELECT r.region_name, COUNT(t.consumer_id) AS total_transactions\n",
        "FROM world_regions r\n",
        "LEFT JOIN user_nodes u ON r.region_id = u.region_id\n",
        "LEFT JOIN user_transaction t ON u.consumer_id = t.consumer_id\n",
        "GROUP BY r.region_name\n",
        "HAVING COUNT(t.consumer_id) > 0;\n",
        "==========================================\n",
        "SELECT r.region_name, SUM(t.transaction_amount) AS total_deposit_amount\n",
        "FROM world_regions r\n",
        "LEFT JOIN user_nodes u ON r.region_id = u.region_id\n",
        "INNER JOIN user_transaction t ON u.consumer_id = t.consumer_id\n",
        "WHERE t.transaction_type = 'deposit'\n",
        "GROUP BY r.region_name;\n",
        "===============================================\n",
        "SELECT t.consumer_id, SUM(t.transaction_amount) AS total_transaction_amount\n",
        "FROM user_transaction t\n",
        "WHERE t.transaction_type = 'deposit'\n",
        "GROUP BY t.consumer_id\n",
        "ORDER BY total_transaction_amount DESC\n",
        "LIMIT 5;\n",
        "=========================================\n",
        "SELECT r.region_id, r.region_name, COUNT(DISTINCT u.consumer_id) AS num_of_customers\n",
        "FROM world_regions r\n",
        "INNER JOIN user_nodes u ON r.region_id = u.region_id\n",
        "GROUP BY r.region_id, r.region_name;\n",
        "===========================================\n",
        "SELECT transaction_type, COUNT(DISTINCT consumer_id) AS unique_count, SUM(transaction_amount) AS total_amount\n",
        "FROM user_transaction\n",
        "GROUP BY transaction_type;\n",
        "===========================================\n",
        "SELECT\n",
        "    'deposit' AS txn_type,\n",
        "    ROUND(AVG(deposit_count), 0) AS avg_deposit_count,\n",
        "    ROUND(AVG(deposit_amount), 0) AS avg_deposit_amount\n",
        "FROM (\n",
        "    SELECT\n",
        "        consumer_id,\n",
        "        SUM(CASE WHEN transaction_type = 'deposit' THEN 1 ELSE 0 END) AS deposit_count,\n",
        "        SUM(CASE WHEN transaction_type = 'deposit' THEN transaction_amount ELSE 0 END) AS deposit_amount\n",
        "    FROM user_transaction\n",
        "    GROUP BY consumer_id\n",
        ") AS deposit_summary;\n",
        "===============================================\n",
        "SELECT r.region_name, COUNT(t.transaction_type) AS num_transactions\n",
        "FROM world_regions r\n",
        "LEFT JOIN user_nodes u ON r.region_id = u.region_id\n",
        "LEFT JOIN user_transaction t ON u.consumer_id = t.consumer_id\n",
        "GROUP BY r.region_name\n",
        "HAVING COUNT(t.transaction_type) > 0;"
      ],
      "metadata": {
        "id": "84aYdh_psAl5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}